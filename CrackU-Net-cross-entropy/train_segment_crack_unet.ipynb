{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3925,
     "status": "ok",
     "timestamp": 1592010995143,
     "user": {
      "displayName": "Yunpeng Deng",
      "photoUrl": "",
      "userId": "11828948728824100341"
     },
     "user_tz": -480
    },
    "id": "Je-jZlZw98JR",
    "outputId": "979cee24-255e-4df3-af68-c85fc3610c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # 查看GPU信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12149,
     "status": "error",
     "timestamp": 1592011003395,
     "user": {
      "displayName": "Yunpeng Deng",
      "photoUrl": "",
      "userId": "11828948728824100341"
     },
     "user_tz": -480
    },
    "id": "ErvIucUC98Jd",
    "outputId": "94953f40-3079-4ecf-81bf-6d1ef626258b"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSlUNuJi98Jj"
   },
   "outputs": [],
   "source": [
    "# 进入需要训练项目的文件夹\n",
    "%cd /content/drive/My Drive/Colab Notebooks/ML2020_spring_crack_detection/CrackU-Net-cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0c0pIzFBn75"
   },
   "outputs": [],
   "source": [
    "!pip install xlutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBSpRY0i98Ju"
   },
   "outputs": [],
   "source": [
    "from models_crack_unet import SegmentNet, weights_init_normal\n",
    "from dataset_crack_unet import CFDDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import PIL.Image as Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xlwt\n",
    "import xlrd\n",
    "from xlutils.copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrIvveOM98Jz"
   },
   "outputs": [],
   "source": [
    "# 在ipynb文件中，parse的创建用函数来创建\n",
    "# 直接用parser=parser = argparse.ArgumentParser() 来创建之后调用会报错\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--cuda\", type=bool, default=True, help=\"number of gpu\")\n",
    "    parser.add_argument(\"--gpu_num\", type=int, default=1, help=\"number of gpu\")\n",
    "    parser.add_argument(\"--worker_num\", type=int, default=0, help=\"number of input workers\") # 只有一个GPU,default=0表示单进程加载\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=6, help=\"batch size of input\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01, help=\"adam: learning rate\")\n",
    "    parser.add_argument(\"--b1\", type=float, default=0.90, help=\"adam: decay of first order momentum of gradient\")\n",
    "    parser.add_argument(\"--b2\", type=float, default=0.997, help=\"adam: decay of first order momentum of gradient\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.0005, help=\"adam: weight decay coefficient\")\n",
    "\n",
    "    parser.add_argument(\"--begin_epoch\", type=int, default=1, help=\"begin_epoch\")\n",
    "    parser.add_argument(\"--end_epoch\", type=int, default=201, help=\"end_epoch\")\n",
    "\n",
    "    parser.add_argument(\"--need_test\", type=bool, default=True, help=\"need to test\")\n",
    "    parser.add_argument(\"--test_interval\", type=int, default=10, help=\"interval of test\")\n",
    "    parser.add_argument(\"--need_save\", type=bool, default=True, help=\"need to save\")\n",
    "    parser.add_argument(\"--save_interval\", type=int, default=10, help=\"interval of save weights\")\n",
    "\n",
    "    parser.add_argument(\"--img_width\", type=int, default=480, help=\"size of image width\")\n",
    "    parser.add_argument(\"--img_height\", type=int, default=320, help=\"size of image height\")\n",
    "    \n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "opt = get_arguments()\n",
    "\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnHkdMxx98J7"
   },
   "outputs": [],
   "source": [
    "dataSetRoot = \"../Data_cleaned\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lrEnbFb98KA"
   },
   "outputs": [],
   "source": [
    "# 建立网络\n",
    "segment_net = SegmentNet(init_weights=True)\n",
    "\n",
    "# 选择二分类交叉熵损失函数\n",
    "criterion_segment  = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7x5y3H098KK"
   },
   "outputs": [],
   "source": [
    "# 选择Adam优化器\n",
    "optimizer_seg = torch.optim.Adam(segment_net.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2), weight_decay=opt.weight_decay)\n",
    "\n",
    "# 指数方式调整学习率，每一个epoch之后学习率变为原来的0.98倍\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer_seg, gamma=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqkKSXpG98KF"
   },
   "outputs": [],
   "source": [
    "# 选择训练环境和参数\n",
    "if opt.cuda:\n",
    "    segment_net = segment_net.cuda()\n",
    "    criterion_segment.cuda()\n",
    "\n",
    "if opt.gpu_num > 1:\n",
    "    segment_net = torch.nn.DataParallel(segment_net, device_ids=list(range(opt.gpu_num)))\n",
    "\n",
    "if opt.begin_epoch != 1:\n",
    "    # 加载前期训练的模型\n",
    "    segment_net.load_state_dict(torch.load(\"./saved_models/segment_net_%d.pth\" % (opt.begin_epoch-1)))\n",
    "else:\n",
    "    # 初始化权重\n",
    "    segment_net.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cys8eeMh98KP"
   },
   "outputs": [],
   "source": [
    "# 对原始数据和真实值进行一定前期处理，方便后续训练\n",
    "transforms_ = transforms.Compose([\n",
    "    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transforms_mask = transforms.Compose([\n",
    "    transforms.Resize((opt.img_height, opt.img_width)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STNFdFYe98KU"
   },
   "outputs": [],
   "source": [
    "# 加载训练集和测试集\n",
    "trainCFDloader = DataLoader(\n",
    "    CFDDataset(dataSetRoot, transforms_=transforms_, transforms_mask= transforms_mask, subFold=\"CFD\", isTrain=True),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.worker_num,\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    CFDDataset(dataSetRoot, transforms_=transforms_, transforms_mask= transforms_mask,  subFold=\"CFD/cfd_TEST\", isTrain=True),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.worker_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msQjqbFDsBsu"
   },
   "outputs": [],
   "source": [
    "# 定义对输出结果进行阈值化处理的函数，将小于阈值的计算为0，大于阈值的计算为1，在图像中像素为1的点为白色，为0的点为黑色\n",
    "def data_threshold(data, threshold):\n",
    "    threshold = torch.Tensor([threshold]).cuda()\n",
    "    data_target = torch.Tensor([i//threshold for i in data]).cuda()\n",
    "    return data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJPMOhJRrdra"
   },
   "outputs": [],
   "source": [
    "# 获取训练之后的 accuracy, precision , recall ,F1评价指标\n",
    "# mask是真实值，data是预测值\n",
    "def evaluate_metric(mask, data):\n",
    "    m = metrics.confusion_matrix(mask, data)\n",
    "    count_TP = m[1, 1]\n",
    "    count_TN = m[0, 0]\n",
    "    count_FN = m[1, 0] \n",
    "    count_FP = m[0 ,1]\n",
    "    \n",
    "    count = count_TP + count_FN + count_FP +count_TN\n",
    "    print(\"count:{0},TP:{1},TN:{2},FP:{3},FN:{4}\".format(count, count_TP, count_TN, count_FP, count_FN))  \n",
    "    \n",
    "    # 准确率\n",
    "    accuracy = (count_TP+count_TN)/count \n",
    "    # 精准率\n",
    "    precision = count_TP / (count_TP + count_FP) \n",
    "    # 查全率\n",
    "    recall = count_TP / (count_TP + count_FN)\n",
    "    # F1分\n",
    "    F1 = 2*count_TP/(2*count_TP + count_FP + count_FN)\n",
    "    \n",
    "    return accuracy, precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nlxv5rtP-EyV"
   },
   "outputs": [],
   "source": [
    "if opt.begin_epoch == 1:\n",
    "  # 将训练过程的需要保存的数据保存到xls文件中\n",
    "  # 创建一个workbook，设置编码\n",
    "  workbook = xlwt.Workbook(encoding = 'utf-8')\n",
    "\n",
    "  #---------------------写入训练过程的epoch, loss, accuracy------------------\n",
    "  # 创建一个worksheet\n",
    "  worksheet = workbook.add_sheet('sheet1')\n",
    "  worksheet.write(0, 0, 'epoch')\n",
    "  worksheet.write(0, 1, 'loss')\n",
    "  worksheet.write(0, 2, 'accuracy')\n",
    "\n",
    "  #---------------------写入测试过程的epoch, loss, accuracy------------------\n",
    "  worksheet = workbook.add_sheet('sheet2')\n",
    "  worksheet.write(0, 0, 'epoch')\n",
    "  worksheet.write(0, 1, 'loss')\n",
    "  worksheet.write(0, 2, 'accuracy')\n",
    "                  \n",
    "  #---------------------写入测试过程的epoch, accuracy, precision, recall, F1------------------                \n",
    "  worksheet = workbook.add_sheet('sheet3')\n",
    "  worksheet.write(0, 0, 'epoch')\n",
    "  worksheet.write(0, 1, 'accuracy')\n",
    "  worksheet.write(0, 2, 'precision')\n",
    "  worksheet.write(0, 3, 'recall')\n",
    "  worksheet.write(0, 4, 'F1')\n",
    "\n",
    "  # 保存\n",
    "  workbook.save('evaluate_data.xls')\n",
    "\n",
    "def write_excel_xls_append(path, value, sheet_num):\n",
    "  index = len(value)  # 获取需要写入数据的行数\n",
    "  workbook = xlrd.open_workbook(path)            # 打开工作簿\n",
    "  sheets = workbook.sheet_names()                # 获取工作簿中的所有表格\n",
    "  worksheet = workbook.sheet_by_name(sheets[sheet_num])  # 获取工作簿中所有表格中的的第一个表格\n",
    "  rows_old = worksheet.nrows                 # 获取表格中已存在的数据的行数\n",
    "  new_workbook = copy(workbook)                # 将xlrd对象拷贝转化为xlwt对象\n",
    "  new_worksheet = new_workbook.get_sheet(sheet_num)      # 获取转化后工作簿中的第sheet_num个表格\n",
    "  \n",
    "  for i in range(0, index):\n",
    "      new_worksheet.write(rows_old, i, value[i])  # 追加写入数据\n",
    "  new_workbook.save(path)  # 保存工作簿\n",
    "  print(\"xls格式表格[追加]写入数据成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AljlVei798Kd"
   },
   "outputs": [],
   "source": [
    "for epoch in range(opt.begin_epoch, opt.end_epoch):\n",
    "\n",
    "  iterCFD = trainCFDloader.__iter__()\n",
    "\n",
    "  lenNum = len(trainCFDloader)\n",
    "\n",
    "  segment_net.train()\n",
    "\n",
    "  # -----------------------------------------------------------------------------\n",
    "  # 开始训练\n",
    "  # 记录每一个epoch的总损失和总精度\n",
    "  train_loss_sum, train_acc_sum, batch_count = 0.0, 0.0, 0.0\n",
    "\n",
    "  for i in range(0, lenNum):\n",
    "      \n",
    "    batchData = iterCFD.__next__()\n",
    "\n",
    "    if opt.cuda:\n",
    "        img = batchData[\"img\"].cuda()\n",
    "        mask = batchData[\"mask\"].cuda()\n",
    "    else:\n",
    "        img = batchData[\"img\"]\n",
    "        mask = batchData[\"mask\"]\n",
    "\n",
    "    optimizer_seg.zero_grad()\n",
    "\n",
    "    rst = segment_net(img)\n",
    "    seg = rst[\"seg\"]\n",
    "\n",
    "    # 计算训练过程的损失loss\n",
    "    loss_seg = criterion_segment(seg, mask)\n",
    "    loss_seg.backward()\n",
    "    optimizer_seg.step()\n",
    "\n",
    "    train_loss_sum += loss_seg.item() \n",
    "    \n",
    "    # 计算训练过程的accuracy\n",
    "    net_seg = data_threshold(seg.clone().flatten(), 0.5)    # 预测值\n",
    "    mask_seg = mask.clone().flatten()              # 真实值\n",
    "    \n",
    "    # 对每个像素点的值进行比较，相同的点计入right_seg \n",
    "    right_seg = torch.eq(net_seg, mask_seg).sum().float().item()\n",
    "    total_num = float(mask.clone().flatten().size()[0])\n",
    "    \n",
    "    batch_acc = right_seg/total_num\n",
    "    train_acc_sum += batch_acc\n",
    "    \n",
    "    batch_count += 1\n",
    "    \n",
    "    # 输出每个epoch之中每个batch的信息\n",
    "    print(\"[Epocn:{0}],[batch_count:{1}],[loss:{2:.6f}],[accuracy:{3:.6f}]\".format(epoch, batch_count, loss_seg.item(), batch_acc))\n",
    "    \n",
    "  # 输出训练过程每个epoch平均的loss和accuracy\n",
    "  print(\"[Epoch {0}/{1}], [loss:{2:.6f}], accuracy:{3:.6f}]\".format(epoch, opt.end_epoch, train_loss_sum/batch_count, train_acc_sum/batch_count))\n",
    "    \n",
    "  # 将上述epoch, loss, accuracy数据写入xls文件\n",
    "  print(\"------------------------------------------------------------------------------------------\")\n",
    "  print(\"开始写入训练过程的epoch, loss, accuracy\")\n",
    "  train_xls_value = [epoch, train_loss_sum/batch_count, train_acc_sum/batch_count]\n",
    "  write_excel_xls_append(\"evaluate_data.xls\", train_xls_value, 0)\n",
    "  print(\"------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "\n",
    "  # -----------------------------------------------------------------------------\n",
    "  # 以一定周期保存训练之后的模型\n",
    "  if opt.need_save and epoch % opt.save_interval == 0 and epoch >= opt.save_interval:\n",
    "\n",
    "    save_path_str = \"./saved_models\"\n",
    "    if os.path.exists(save_path_str) == False:\n",
    "        os.makedirs(save_path_str, exist_ok=True)\n",
    "\n",
    "    torch.save(segment_net.state_dict(), \"%s/segment_net_%d.pth\" % (save_path_str, epoch))\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(\"save weights ! epoch = %d\" %epoch)\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    pass\n",
    "    \n",
    "\n",
    "  # -----------------------------------------------------------------------------\n",
    "  # 对模型进行测试，并保存结果\n",
    "  if opt.need_test and epoch % opt.test_interval == 0 and epoch >= opt.test_interval:\n",
    "\n",
    "    test_loss_sum, test_acc_sum, batch_count = 0.0, 0.0, 0.0\n",
    "    result_evaluate_epoch = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "    for i, testBatch in enumerate(testloader):\n",
    "      imgTest = testBatch[\"img\"].cuda()\n",
    "      t1 = time.time()\n",
    "      rstTest = segment_net(imgTest)\n",
    "      t2 = time.time()\n",
    "\n",
    "      # 计算测试过程的损失loss\n",
    "      mask = testBatch[\"mask\"].cuda()\n",
    "      loss_test = criterion_segment(rstTest[\"seg\"], mask)\n",
    "\n",
    "      test_loss_sum += loss_test.item()\n",
    "\n",
    "      # 计算测试过程的accuracy\n",
    "      net_seg = data_threshold(rstTest[\"seg\"].clone().flatten(), 0.5)  # 预测值\n",
    "      mask_seg = mask.clone().flatten()                  # 真实值\n",
    "      \n",
    "      # 对每个像素点的值进行比较，相同的点计入right_seg \n",
    "      right_seg = torch.eq(net_seg, mask_seg).sum().float().item()\n",
    "      total_num = float(mask.clone().flatten().size()[0])\n",
    "      \n",
    "      batch_acc = right_seg/total_num\n",
    "      test_acc_sum += batch_acc\n",
    "      \n",
    "      batch_count += 1\n",
    "\n",
    "      # 对一个batch测试结果进行综合评估，并进行累加，方便后续保存\n",
    "      result_evaluate_batch = np.array(list(evaluate_metric(mask_seg, net_seg)))\n",
    "      result_evaluate_epoch += result_evaluate_batch\n",
    "      \n",
    "      # 对保存的图片进行阈值化处理\n",
    "      seg_shape = rstTest[\"seg\"].data.shape\n",
    "      segTest_flatten = data_threshold(rstTest[\"seg\"].flatten(), 0.5)\n",
    "      segTest = segTest_flatten.reshape(seg_shape[0], seg_shape[1], seg_shape[2], seg_shape[3])\n",
    "\n",
    "      # 建立文件的保存路径\n",
    "      save_path_str = \"./testResultSeg/epoch_%d\"%(epoch)\n",
    "      if os.path.exists(save_path_str) == False:\n",
    "          os.makedirs(save_path_str, exist_ok=True)\n",
    "\n",
    "      # 输出文件的保存信息\n",
    "      print(\"processing image NO %d, time comsuption %fs\"%(i, t2 - t1))\n",
    "      save_image(imgTest.data, \"%s/img_%d.jpg\"% (save_path_str, i))\n",
    "      save_image(segTest.data, \"%s/img_%d_seg.jpg\"% (save_path_str, i))\n",
    "\n",
    "    # 将上述测试过程的评估参数acc,precision,recall和F1分数进行保存\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(\"开始写入评估参数\")\n",
    "    result_evaluate_epoch = result_evaluate_epoch/np.array([batch_count])\n",
    "    test_xls_metric = [epoch] + list(result_evaluate_epoch)\n",
    "    write_excel_xls_append(\"evaluate_data.xls\", test_xls_metric, 2)\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # 输出测试过程每个epoch平均的loss和accuracy\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(\"[Epoch {0}/{1}], [loss:{2:.6f}], accuracy:{3:.6f}]\".format(epoch, opt.end_epoch, test_loss_sum/batch_count, test_acc_sum/batch_count))\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    # 将上述epoch, loss, accuracy数据写入xls文件\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    print(\"开始写入测试过程的epoch, loss, accuracy\")\n",
    "    test_xls_value = [epoch, test_loss_sum/batch_count, test_acc_sum/batch_count]\n",
    "    write_excel_xls_append(\"evaluate_data.xls\", test_xls_value, 1)\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  # 利用schedular对学习率进行调节\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pS80j6duZzZM"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Bf6xTaWMOWP"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_segment_crack_unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
